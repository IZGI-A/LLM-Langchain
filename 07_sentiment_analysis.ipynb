{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JnlL-VONply"
      },
      "source": [
        "# Discover Sentiment Analysis\n",
        "\n",
        "\n",
        "We'll start with a dictionnary based approach with the [textblob](https://github.com/sloria/textblob) library.\n",
        "\n",
        "Note that using textblob for sentiment analysis is fine for a quick and dirty sentiment scoring but would not be reliable in a more serious project. The results are too dependent on polarity scores of specific words.\n",
        "\n",
        "We start by installing the library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ZroV1qNplz",
        "outputId": "2eb0bc4e-bd91-47e8-83ba-d791aa98931b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "# install textblob\n",
        "\n",
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9sFQIkDNplz",
        "outputId": "8cf7fe0d-3c63-4847-c211-6d6774d66980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity \t Subjectivity \t Sentence\n",
            "    -0.2\t          0.4 \t That was a narrow escape, Alice said.\n",
            "    0.35\t         0.55 \t A good deal frightened at the sudden change.\n",
            "    0.65\t          1.0 \t But very glad to find herself still in existence;\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = \"That was a narrow escape, Alice said. A good deal frightened at the sudden change. But very glad to find herself still in existence;\"\n",
        "blob = TextBlob(text)\n",
        "print(\"Polarity \\t Subjectivity \\t Sentence\")\n",
        "for sentence in blob.sentences:\n",
        "    print(f\"{sentence.sentiment.polarity:8}\\t {sentence.sentiment.subjectivity:12} \\t {sentence.raw}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE6C4uPvNplz"
      },
      "source": [
        "The polarity score (0.35) of the second sentence \"A good deal frightened at the sudden change.\" is not correct. It should be negative.\n",
        "\n",
        "Let's see what's happening here by calculating the polarity for different versions of that sentence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5GF7eKXNpl0",
        "outputId": "e8605888-6a98-4e4d-c5e6-117edc6d9127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0.7 \t A good deal frightened at the change.\n",
            "  0.0 \t Frightened at the change.\n",
            "  0.8 \t Happy at the change.\n",
            "  0.2 \t Very frightened at the change.\n"
          ]
        }
      ],
      "source": [
        "def polarity(text):\n",
        "    polarity_score = TextBlob(text).sentences[0].sentiment.polarity\n",
        "    print(f\"{polarity_score:5} \\t {text}\")\n",
        "    return\n",
        "\n",
        "# original sentence, positive\n",
        "polarity(\"A good deal frightened at the change.\")\n",
        "\n",
        "# remove 'a good deal', you get neutral\n",
        "polarity(\"Frightened at the change.\")\n",
        "\n",
        "# what if we add a negation, and change the noun\n",
        "polarity(\"Happy at the change.\")\n",
        "\n",
        "# or add just the word very\n",
        "polarity(\"Very frightened at the change.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au858_KoNpl0"
      },
      "source": [
        "Frightened is considered a verb and is not taken into the polarity score although it's a negative word.\n",
        "\n",
        "The polarity score obtained with textblob is not very reliable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oXE0UhONpl0"
      },
      "source": [
        "# Google NLP\n",
        "\n",
        "Check out the Google NLP Quickstart documentation, [found here](https://cloud.google.com/natural-language/docs/quickstart), to learn how to register and obtain an API key.\n",
        "\n",
        "You can also use the [demo page](https://cloud.google.com/natural-language)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l-uX3IhNpl0"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "key = { \"key\": \"<Your API KEY here>\"}\n",
        "\n",
        "if key[\"key\"] != \"<Your API KEY here>\":\n",
        "\n",
        "    data = {\n",
        "        \"document\": {\n",
        "            \"type\":\"PLAIN_TEXT\",\n",
        "            \"content\":\"Alice was very frightened.\"\n",
        "        },\n",
        "        \"encodingType\":\"UTF8\"\n",
        "    }\n",
        "    results = requests.post(url, params=key, json=data)\n",
        "\n",
        "    content = results.content.decode('utf-8')\n",
        "    json.loads(content)['documentSentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP2Xb5owNpl0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}