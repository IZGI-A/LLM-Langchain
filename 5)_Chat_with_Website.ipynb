{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4I9WNYmHZxDz",
        "outputId": "3989a312-fd78-42e1-b9fb-b4f9d2431fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.7 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trafilatura\n",
            "  Downloading trafilatura-1.6.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from trafilatura) (2023.7.22)\n",
            "Collecting courlan>=0.9.4 (from trafilatura)\n",
            "  Downloading courlan-0.9.4-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting htmldate>=1.5.1 (from trafilatura)\n",
            "  Downloading htmldate-1.5.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting justext>=3.0.0 (from trafilatura)\n",
            "  Downloading jusText-3.0.0-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (4.9.3)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (2.0.4)\n",
            "Requirement already satisfied: langcodes>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=0.9.4->trafilatura) (3.3.0)\n",
            "Collecting tld>=0.13 (from courlan>=0.9.4->trafilatura)\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dateparser>=1.1.2 (from htmldate>=1.5.1->trafilatura)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.5.1->trafilatura) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (2023.3.post1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (2023.6.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->htmldate>=1.5.1->trafilatura) (1.16.0)\n",
            "Installing collected packages: tld, justext, dateparser, courlan, htmldate, trafilatura\n",
            "Successfully installed courlan-0.9.4 dateparser-1.1.8 htmldate-1.5.1 justext-3.0.0 tld-0.13 trafilatura-1.6.2\n",
            "Collecting asyncio\n",
            "  Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: asyncio\n",
            "Successfully installed asyncio-3.4.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "asyncio"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain openai\n",
        "!pip install trafilatura\n",
        "!pip install asyncio\n",
        "!pip install dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lc-9fF16Zyem"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import BaseTool\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pydantic import Field\n",
        "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain, BaseCombineDocumentsChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os, asyncio, trafilatura\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "OPENAI_API_KEY = \"enter_your_api\"\n",
        "\n",
        "def _get_text_splitter():\n",
        "    return RecursiveCharacterTextSplitter(\n",
        "        # Set a really small chunk size, just to show.\n",
        "        chunk_size = 500,\n",
        "        chunk_overlap  = 20,\n",
        "        length_function = len,\n",
        "    )\n",
        "\n",
        "class WebpageQATool(BaseTool):\n",
        "    name = \"query_webpage\"\n",
        "    description = \"Browse a webpage and retrieve the information relevant to the question.\"\n",
        "    text_splitter: RecursiveCharacterTextSplitter = Field(default_factory=_get_text_splitter)\n",
        "    qa_chain: BaseCombineDocumentsChain\n",
        "\n",
        "    def _run(self, question: str) -> str:\n",
        "        result = trafilatura.extract(trafilatura.fetch_url(url))\n",
        "        docs = [Document(page_content=result, metadata={\"source\": url})]\n",
        "        web_docs = self.text_splitter.split_documents(docs)\n",
        "        results = []\n",
        "        for i in range(0, len(web_docs), 4):\n",
        "            input_docs = web_docs[i:i+4]\n",
        "            window_result = self.qa_chain({\"input_documents\": input_docs, \"question\": question}, return_only_outputs=True)\n",
        "            results.append(f\"Response from window {i} - {window_result}\")\n",
        "        results_docs = [Document(page_content=\"\\n\".join(results), metadata={\"source\": url})]\n",
        "        return self.qa_chain({\"input_documents\": results_docs, \"question\": question}, return_only_outputs=True)\n",
        "\n",
        "    async def _arun(self, url: str, question: str) -> str:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=1.0)\n",
        "query_website_tool = WebpageQATool(qa_chain=load_qa_with_sources_chain(llm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymjAGLJdDSgg",
        "outputId": "12158c29-9ae1-49fc-b349-349b2ff09a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'output_text': 'Bu site, İspanyolca öğrenmeye yönelik kaynaklar ve dersler sunan bir web sitesidir. Site, başlangıç seviyesinde başlayabileceğiniz basit İspanyolca dersleri ve video formatında içerikler sunmaktadır. Ayrıca \"Yeni Başlayanlar için Temel İspanyolca\" adlı bir kitabın belli bir bölümünü içeren e-kitabı indirme imkanı da sunulmaktadır. Site ayrıca İspanyolca öğrenme konusunda yardımcı kaynaklar sunmaktadır.\\nSOURCES: https://www.ispanyol.com'}\n"
          ]
        }
      ],
      "source": [
        "url = \"https://www.ispanyol.com\"\n",
        "print(query_website_tool.run(\"bu site ne hakkında?\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
