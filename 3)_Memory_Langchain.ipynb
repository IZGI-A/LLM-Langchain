{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10074,"status":"ok","timestamp":1694256310671,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"ALSfzcYpKewR","outputId":"c542e8a3-1a9c-4fe7-b0f3-296b5d77fc27"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -qU langchain openai tiktoken"]},{"cell_type":"markdown","metadata":{"id":"12VtazJEbvQm"},"source":["## What you will learn\n","\n","- How to use memory in Langchain\n","- ConversationalBufferMemory\n","- ConversationSummaryBufferMemory"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3897,"status":"ok","timestamp":1694256343101,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"S5pkZd9Y8td-"},"outputs":[],"source":["from langchain import OpenAI, PromptTemplate\n","from langchain.chains import LLMChain, ConversationChain, LLMMathChain, TransformChain, SequentialChain, SimpleSequentialChain\n","\n","from langchain.chains.conversation.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1694256345146,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"PWnKwCsp84rR"},"outputs":[],"source":["OPENAI_API_KEY = \"enter_your_api\""]},{"cell_type":"markdown","metadata":{"id":"2yRzxW1j-JSs"},"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1694256392903,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"nyH6W7r188pF"},"outputs":[],"source":["llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"CJDD_g3V-HFC"},"source":["\n","## ConversationBufferMemory\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1694256397785,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"ciAxpCQH9BOe"},"outputs":[],"source":["memory = ConversationBufferMemory()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1694256400985,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"RP-RVeZt9DUG"},"outputs":[],"source":["conversation = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    memory=memory\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":259},"executionInfo":{"elapsed":1020,"status":"ok","timestamp":1694256410163,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"m7WN5n_69FV3","outputId":"1b15ac30-029f-45c3-c9cd-789ee078354e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Merhaba, benim adım Giray!\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Merhaba Giray! Benim adım AI. Ne hakkında konuşmak istersin?'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"Merhaba, benim adım Giray!\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"elapsed":1036,"status":"ok","timestamp":1694256567977,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"4DuqfKfU9OQl","outputId":"dbda3aa6-3a18-4cc3-f1c8-146107380305"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Merhaba, benim adım Giray!\n","AI:  Merhaba Giray! Benim adım AI. Ne hakkında konuşmak istersin?\n","Human: Benim adım ne?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Senin adın Giray.'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"Benim adım ne?\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":327},"executionInfo":{"elapsed":1801,"status":"ok","timestamp":1694256572530,"user":{"displayName":"İrem Zehra Altun","userId":"16600170792609462832"},"user_tz":-180},"id":"RYQ6BO1i9U5V","outputId":"fad1a4d1-74ff-487b-b022-52670e26fb6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Merhaba, benim adım Giray!\n","AI:  Merhaba Giray! Benim adım AI. Ne hakkında konuşmak istersin?\n","Human: Benim adım ne?\n","AI:  Senin adın Giray.\n","Human: Bir maruzatım var, şahsım ve ben bir yazılımcı şakası dinlemek istiyor. En komik yazılımcı şakası yaz.\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'  İyi bir yazılımcı şakası mı? İşte burada bir tane: \"Bir yazılımcı, bir araba satın almak istediğinde, arabayı satın almak için bir kod yazmaya çalışıyor.\"'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["conversation.predict(input=\"Bir maruzatım var, şahsım ve ben bir yazılımcı şakası dinlemek istiyor. En komik yazılımcı şakası yaz.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXNpayFZ9gtD"},"outputs":[],"source":["conversation.predict(input=\"Yaptığın şaka neydi?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Lq3u8fL9o4e"},"outputs":[],"source":["print(conversation.memory.buffer)"]},{"cell_type":"markdown","metadata":{"id":"IZd695dv9yhq"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","## *ConversationSummaryBufferMemory*\n","\n","---\n","ConversationSummaryBufferMemory keeps a summary of the previous conversation\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Er3kxFV4-EOW"},"outputs":[],"source":["memory_summary = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n","conversation_with_summary = ConversationChain(\n","    llm=llm,\n","    memory=ConversationSummaryBufferMemory(llm=llm, max_token_limit=40),\n","    verbose=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXHLDNyc-0oi"},"outputs":[],"source":["conversation_with_summary.predict(input=\"Merhaba ben Giray\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psUXUs7VCCh5"},"outputs":[],"source":["conversation_with_summary.predict(input=\"Benim butik bir restorantım var.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oN_hrVyAAS8c"},"outputs":[],"source":["conversation_with_summary.predict(input=\"Bir müşteri geld, sonradan görme belli, iki kişi için 4 kişilik karışık kebap sipariş etti.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0nU1XIK_tzz"},"outputs":[],"source":["conversation_with_summary.predict(input=\"Kebapların içinde altın tozu olmadığına emin olmanı istiyorum.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QETHXHWu_0c8"},"outputs":[],"source":["print(conversation_with_summary.memory.moving_summary_buffer)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
